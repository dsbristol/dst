---
title: 10.0 Parallel Algorithms
layout: coursebook
---
# 10 Parallel Algorithms

In this block we cover:

* What is a parallel computer?
* How to design code that parallelises
* Parallelism and complexity
* Computation graphs
* How to conceptualise parallelism, including:
  * Vectorisation
  * Reduce and accumulate
  * Map, and Map-Reduce
* Practical experience with parallelism, including:
  * Benchmarking code
  * the `multiprocessing` parallelisation library
  * Map, starmap, accumulate, reduce in python
  * Asynchronous and synchronous parallelisation
  * Running parallelized scripts from inside Jupyter (cross platform solution)

## Lectures

*  [Introduction to Parallelism]({{ site.data.block10.s01.url }})
*  [Vectorisation, Mapping and Reducing]({{ site.data.block10.s02.url }})

## Worksheets:

* [Worksheet 10.1 Parallel Algorithms]({{ site.data.block10.ws01.url }}) 
* [Portfolio 10]({{ site.data.block10.portfolio.url }})

## Workshop:

* [10.3 Workshop on Coding Parallel Algorithms]({{ site.data.block10.s03.url }})

## References

* Chapter 27 of Cormen et al 2010 [Introduction to Algorithms](https://github.com/mejibyte/competitive_programming/blob/master/lib/Books/Introduction.to.Algorithms.3rd.Edition.Sep.2010.pdf) covers some of these concepts.
* [Numpy vectorisation](https://realpython.com/numpy-array-programming/)
* [MapReduce algorithm for matrix multiplication](http://www.mathcs.emory.edu/~cheung/Courses/554/Syllabus/9-parallel/matrix-mult.html)
* [A Brief Overview of Parallel Algorithms](http://www.cs.cmu.edu/~scandal/html-papers/short/short.html)
* [Parallel computing concepts](https://csinparallel.org/csinparallel/modules/intro_parallel.html)
e.g. Amdahl's Law for the overall speedup
* [MISD/MIMD/SIMD/SISD](https://www.tutorialspoint.com/parallel_algorithm/parallel_algorithm_introduction.htm)
* [Parallel time complexity](https://www.tutorialspoint.com/parallel_algorithm/parallel_algorithm_analysis.htm)

Previous: [Block 09](09.md).
Next: [Block 11](cb-old/coursebook/11.md).
