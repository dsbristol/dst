{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10.3 Coding Parallel Algorithms\n",
    "\n",
    "```\n",
    "date: \"Block 10\"\n",
    "author: \"Daniel Lawson\"\n",
    "email: dan.lawson@bristol.ac.uk\n",
    "output: html_document\n",
    "version: 2.0.0\n",
    "```\n",
    "\n",
    "# 0. Introduction\n",
    "\n",
    "Here we will put to practice the ideas described in the lecture, notably:\n",
    "\n",
    "* Vectorisation,\n",
    "* Native Accumulation,\n",
    "* The **Map** function,\n",
    "* The **Reduce** function, and its **accumulate** variant,\n",
    "* The **multiprocessing** environment for parallelisation.\n",
    "\n",
    "Until the final section, everything is only about preparing for parallelism. **Parallel code in python is non-trivial** because it needs to access additional cores that it may not have permission for. There are many different implementations that variously:\n",
    "\n",
    "* Don't work across operating systems,\n",
    "* Don't work in Jupyter but work in native python,\n",
    "* Work in python 2/3 but not vice versa,\n",
    "* Any combination of the above.\n",
    "\n",
    "As a rule, **you should not include parallel code inside a notebook** because it is not likely to be cross-platform. By nature of needing to paralellise, it is worth outsourcing important parallel code to a script and running this remotely.\n",
    "\n",
    "You will find that everything here **works on Notable via Blackboard**. I have also provided script files to complete the same parallelisation in Windows via native python. However the script solution we identify is adequate and is the recommended solution, so if your project group wants to work with parallel code and anyone runs Windows, **This Is The Way**.\n",
    "\n",
    "## 0.1 Prerequisites:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in /Users/madjl/envs/jupyter/lib/python3.10/site-packages (1.24.4)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pipreqs  --savepath requirements-block10.txt /Users/madjl/teach/dst-private/Workshops/__temp_pipreqsnb_folder\n",
      "INFO: Successfully saved requirements file in requirements-block10.txt\n"
     ]
    }
   ],
   "source": [
    "!pipreqsnb --savepath requirements-block10.txt block10-CodingParallelAlgorithms.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "REQUIREMENTS:\n",
      "\n",
      "numpy==1.24.4\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nREQUIREMENTS:\\n\")\n",
    "with open('requirements-block10.txt', 'r') as f:\n",
    "    print(f.read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Vectorisation\n",
    "\n",
    "Vectorisation is straightforward in python (and R). You should always try to code with vectors/arrays, though For loops are sometimes necessary.\n",
    "\n",
    "In python:\n",
    "\n",
    "* For loops aren't intrinsically worse, but they encourage poor coding practice.\n",
    "\n",
    "In R: \n",
    "\n",
    "* For loops are very inefficient. For efficiency you may have to go out of your way to vectorise.\n",
    "\n",
    "In C/C++:\n",
    "\n",
    "* OpenMP allows for loops to be parallelised without any additional effort - just remember to avoid using the results of previous loops.\n",
    "* Modern updates (from C++-11) include many explicit vectorisations, allowing map/reduce vectorisations to be exploited directly.\n",
    "\n",
    "### 1.1 Arrays in Python\n",
    "\n",
    "First, an array representation reminder in python:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a =\n",
      "[[1 2]\n",
      " [3 4]]\n",
      "b =\n",
      "[[1 1]\n",
      " [1 1]]\n"
     ]
    }
   ],
   "source": [
    "a = np.array([[1,2],[3,4]])\n",
    "b = np.array([[1,1],[1,1]])\n",
    "print(\"a =\")\n",
    "print(a)\n",
    "print(\"b =\")\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a + b =\n",
      "[[2 3]\n",
      " [4 5]]\n",
      "a - b =\n",
      "[[0 1]\n",
      " [2 3]]\n"
     ]
    }
   ],
   "source": [
    "# substraction and addition\n",
    "\n",
    "print(\"a + b =\")\n",
    "print(a + b)\n",
    "print(\"a - b =\")\n",
    "print(a - b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a * b =\n",
      "[[1 2]\n",
      " [3 4]]\n"
     ]
    }
   ],
   "source": [
    "# Element wise multiplication\n",
    "print(\"a * b =\")\n",
    "print(a*b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a@b =\n",
      "[[3 3]\n",
      " [7 7]]\n",
      "np.dot(a,b) =\n",
      "[[3 3]\n",
      " [7 7]]\n"
     ]
    }
   ],
   "source": [
    "# Matrix multiplication\n",
    "print(\"a@b =\")\n",
    "print(a@b)\n",
    "print(\"np.dot(a,b) =\")\n",
    "print(np.dot(a,b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c.shape =\n",
      "(3,)\n",
      "d.shape\n",
      "(3, 1)\n"
     ]
    }
   ],
   "source": [
    "# numpy array with one row\n",
    "c =  np.array([1,2,3])\n",
    "print(\"c.shape =\")\n",
    "print(c.shape)\n",
    "# numpy array with three rows\n",
    "d = np.array([[1],[2],[3]])\n",
    "print(\"d.shape\")\n",
    "print(d.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 2 3]\n",
      " [4 5 6]\n",
      " [7 8 9]]\n",
      "first element in the array, e[0,0] =\n",
      "1\n",
      "first row of the array. e[0,:] =\n",
      "[1 2 3]\n",
      "second column of the array. e[:,1] =\n",
      "[2 5 8]\n"
     ]
    }
   ],
   "source": [
    "# Define an 3x3 2d array\n",
    "e = np.array([[1,2,3],[4,5,6],[7,8,9]])\n",
    "print(e)\n",
    "print(\"first element in the array, e[0,0] =\")\n",
    "print(e[0,0])\n",
    "print(\"first row of the array. e[0,:] =\")\n",
    "print(e[0,:])\n",
    "print(\"second column of the array. e[:,1] =\")\n",
    "print(e[:,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Comparing loops to vectorisations\n",
    "\n",
    "Now we'll make a simulation to compare between vectorised and non-vectorised code. This is just a simple matrix times vector computation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create some test data and simulate results\n",
    "N=100000 # Number of rows\n",
    "K=200 # Number of columns\n",
    "X = np.random.randn(N,K)\n",
    "W = np.random.rand(K)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def matrix_times_vector_forloop(X,W):\n",
    "    N,K=X.shape\n",
    "    # Initialize theta\n",
    "    forloop = []\n",
    "    for i in range(N):\n",
    "        hypo_i = 0\n",
    "        for j in range(K):\n",
    "            hypo_i += W[j]*X[i,j]\n",
    "        forloop.append(hypo_i)\n",
    "    return(forloop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.07 s, sys: 53.4 ms, total: 3.13 s\n",
      "Wall time: 3.14 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "forloop=matrix_times_vector_forloop(X,W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 43.2 ms, sys: 1.18 ms, total: 44.4 ms\n",
      "Wall time: 11.3 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# matrix format\n",
    "vect = X@W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for loop\n",
      "[3.486372139358113, -3.8682486340192366, 5.694792720080093, -14.342569620284888]\n",
      "vectorised\n",
      "[  3.48637214  -3.86824863   5.69479272 -14.34256962]\n"
     ]
    }
   ],
   "source": [
    "## Check the answers\n",
    "print(\"for loop\")\n",
    "print(forloop[0:4])\n",
    "print(\"vectorised\")\n",
    "print(vect[0:4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CHALLENGE:  Make a plot of how the two approaches change in performance as a function of N (and/or K). What is the computational scaling?\n",
    "\n",
    "See https://towardsdatascience.com/vectorization-implementation-in-machine-learning-ca652920c55d for an example that is much more extreme."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Accumulate example\n",
    "\n",
    "Here we accumulate, i.e. add up all of the values in a vector, either in a vectorised or loop way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5000000,)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq = np.random.randint(0, 100, size=5000000)\n",
    "seq.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cumsum_diff_with_accumulate(x):\n",
    "     x = np.asarray(x)\n",
    "     return np.add.accumulate(x)[-1]\n",
    "def cumsum_diff(x):\n",
    "     sum_px = x[0]\n",
    "     for px in x[1:]:\n",
    "         sum_px = sum_px + px\n",
    "     return sum_px"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 253 ms, sys: 4.82 ms, total: 258 ms\n",
      "Wall time: 256 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "247318336"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "cumsum_diff(seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 17.7 ms, sys: 9 ms, total: 26.7 ms\n",
      "Wall time: 36.7 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "247318336"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "cumsum_diff_with_accumulate(seq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 Mapping and Reducing\n",
    "\n",
    "### 2.1 Map in Python\n",
    "\n",
    "Mapping with python (and R) is straightfoward. \n",
    "\n",
    "Source document: http://chryswoods.com/parallel_python/map.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def calc_distance(point1, point2):\n",
    "    \"\"\"\n",
    "    Function to calculate and return the distance between\n",
    "    two points\n",
    "    \"\"\"\n",
    "    \n",
    "    dx2 = (point1[0] - point2[0]) ** 2\n",
    "    dy2 = (point1[1] - point2[1]) ** 2\n",
    "    dz2 = (point1[2] - point2[2]) ** 2\n",
    "    return math.sqrt(dx2 + dy2 + dz2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<map object at 0x1141ddd50>\n"
     ]
    }
   ],
   "source": [
    "points1 = [(1.0,1.0,1.0), (2.0,2.0,2.0), (3.0,3.0,3.0)]\n",
    "points2 = [(4.0,4.0,4.0), (5.0,5.0,5.0), (6.0,6.0,6.0)]\n",
    "\n",
    "distances = map(calc_distance, points1, points2)\n",
    "\n",
    "print(distances)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Python has not done the calculation! Instead it returns an object (an iterator) that would evaluate this computation. But it does so lazily.  To get the answer, we must use the result, for example, by coercing it to a list.\n",
    "\n",
    "This behaviour is **standard** in parallel processing environments, in which the computation may be performed remotely and there may be additional remote computations to perform. By **caching** the computation, the software environment can sometimes obtain massive efficiency gains.\n",
    "\n",
    "This is how we get the answer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5.196152422706632, 5.196152422706632, 5.196152422706632]\n"
     ]
    }
   ],
   "source": [
    "print(list(distances))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another example, this time with multiple arguments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_smallest(arg1, arg2, arg3):\n",
    "    \"\"\"\n",
    "    Function used to return the smallest value out \n",
    "    of 'arg1', 'arg2' and 'arg3'\n",
    "    \"\"\"\n",
    "\n",
    "    return min(arg1, min(arg2, arg3))\n",
    "\n",
    "a = [1, 2, 3, 4, 5]\n",
    "b = [5, 4, 3, 2, 1]\n",
    "c = [1, 2, 1, 2, 1]\n",
    "\n",
    "result = map(find_smallest, a, b, c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 1, 2, 1]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CHALLENGE: Generalise calc_distance so that it can accept points in any numbers of dimensions.  Generalise find_smallest so that it can accept any number of arguments."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Reduce in Python\n",
    "\n",
    "This is also straightfoward, and exists anagously in R.\n",
    "\n",
    "See http://chryswoods.com/parallel_python/reduce.html\n",
    "\n",
    "Lets start by defining a mapping problem. We will need to define the **add** operation as a **function**, so that we can call it from map and reduce."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7, 9, 11, 13, 15]\n"
     ]
    }
   ],
   "source": [
    "def add(x, y):\n",
    "    \"\"\"Function to return the sum of x and y\"\"\"\n",
    "    return x + y\n",
    "\n",
    "a = [1, 2, 3, 4, 5]\n",
    "b = [6, 7, 8, 9, 10]\n",
    "\n",
    "result = map(add, a, b)\n",
    "\n",
    "print(list(result))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is how we use reduce to automatically apply addition to the entire set of points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55\n"
     ]
    }
   ],
   "source": [
    "from functools import reduce\n",
    "\n",
    "result = map(add, a, b)\n",
    "\n",
    "total = reduce(add, result)\n",
    "\n",
    "print(total)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reduce has an optional third argument which is the initial value that is used as the first value for the reduction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65\n"
     ]
    }
   ],
   "source": [
    "result = map(add, a, b)\n",
    "total = reduce(add, result, 10)\n",
    "print(total)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The standard \"reduce\" function does *not* do anything clever with the computation tree. It simply evaluates the reduction using the sequential definition. That means that it does *not* assume commutivity, which means it can be used with other operations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cat dog mouse fish\n"
     ]
    }
   ],
   "source": [
    "def join_strings(x, y):\n",
    "    return \"%s %s\" % (x,y)\n",
    "c = [\"cat\", \"dog\", \"mouse\", \"fish\"]\n",
    "\n",
    "result = reduce(join_strings, c)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.1 accumulate vs reduce in python\n",
    "\n",
    "Python defines **reduce** to give only the final answer, whereas **accumulate** gives the running total as a list (via an iterator, like map).\n",
    "\n",
    "This is not a universally recognised separation!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7, 16, 27, 40, 55]\n"
     ]
    }
   ],
   "source": [
    "from itertools import accumulate\n",
    "\n",
    "result = map(add, a, b)\n",
    "total = accumulate(result, add)\n",
    "print(list(total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['cat', 'cat dog', 'cat dog mouse', 'cat dog mouse fish']\n"
     ]
    }
   ],
   "source": [
    "print(list(accumulate(c, join_strings)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 parallel implementation\n",
    "\n",
    "multiprocessing python code has to be written into a text file and executed using the python interpreter. It is not recommended to try to run a multiprocessing python script interactively, e.g. via ipython or ipython notebook.\n",
    "\n",
    "This is because the required resources (CPUs) have to be requested from the system and appropriately returned, and the libraries are not reliable across platforms.\n",
    "\n",
    "(it seems to work on linux and mac, but not in windows https://stackoverflow.com/questions/37103243/multiprocessing-pool-in-jupyter-notebook-works-on-linux-but-not-windows)\n",
    "\n",
    "See http://chryswoods.com/parallel_python/multiprocessing.html\n",
    "\n",
    "Multiprocessing achieves parallelism by running multiple copies of your script, but it forces you to write it in a particular way. All imports should be at the top of the script, followed by all function and class definitions. This is to ensure that all copies of the script have access to the same modules, functions and classes. Then, you should ensure that only the master copy of the script runs the code by protecting it behind an ``if __name__ == \"__main__\"`` statement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n"
     ]
    }
   ],
   "source": [
    "print(multiprocessing.cpu_count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Testing if parallelisation works within Jupyter\n",
    "\n",
    "If the following works you should be ok in the notebook; otherwise you will be running via external %run commands, as we do by default.\n",
    "\n",
    "**HEALTH WARNING: The following code willl CRASH your python kernel in Windows and MacOS Big Sur, which will need RESTARTING! So its commented out.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "## this is a test function, reporting happens further down.\n",
    "#from multiprocessing import Pool\n",
    "#def f(x):\n",
    "#    return x**2\n",
    "#if __name__ == \"__main__\":\n",
    "#    pool = Pool(4)\n",
    "#    pool.map(f,range(10))[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Parallelisation for Map-Reduce\n",
    "\n",
    "Here is how we can do a calculation, by writing a script to a file and then running it.\n",
    "\n",
    "The script illustrates the key points:\n",
    "\n",
    "* Distributing compute over cores\n",
    "* Detecting the CPU architecture/count\n",
    "* Ensuring the compute is parallelised\n",
    "* Performing process-specific evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of cores available equals 8\n",
      "The sum of the square of the first 50 integers is 42925\n"
     ]
    }
   ],
   "source": [
    "f = open(\"10.3-pool-multiprocessing.py\", \"w\")\n",
    "f.write(\"\"\"\n",
    "from functools import reduce\n",
    "from multiprocessing import Pool, cpu_count, current_process\n",
    "from time import sleep\n",
    "\n",
    "def square(x):\n",
    "    \\\"\\\"\\\"Function to return the square of the argument\\\"\\\"\\\"\n",
    "    print(\"Worker %s calculating square of %s\" % (current_process().pid, x))\n",
    "    sleep(1)\n",
    "    return x * x\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # print the number of cores\n",
    "    print(\"Number of cores available equals %s\" % cpu_count())\n",
    "    # create a pool of workers\n",
    "    # start all worker processes\n",
    "    pool = Pool(processes= cpu_count())\n",
    "    # create an array of integers, from 1 to N\n",
    "    r = range(1, N+1)\n",
    "    result = pool.map(square, r)\n",
    "\n",
    "    total = reduce(lambda x, y: x + y, result)\n",
    "\n",
    "    print(\"The sum of the square of the first %s integers is %s\" % (N, total))\n",
    "\"\"\")\n",
    "f.close()\n",
    "N=50\n",
    "%run -i 10.3-pool-multiprocessing.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Some notes:**\n",
    "\n",
    "1. Annoyingly, `%run` doesn't always print to the console. If you re-run it, you will get the output as expected from the worker threads.\n",
    "\n",
    "2. Note that here we could have used `%run` (without `-i`) which would **not** have access to anything defined in the jupyter notebook (here the parameter N=50). To run it interactively, and give it access to everything in memory, use `%run -i` (see https://ipython.readthedocs.io/en/stable/interactive/magics.html).\n",
    "\n",
    "On the plus side, everything that was created in the script is available inside of jupyter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Worker 91739 calculating square of 2\n",
      "4\n",
      "The sum of the square of the first 50 integers is 42925\n"
     ]
    }
   ],
   "source": [
    "print(square(2))\n",
    "print(\"The sum of the square of the first %s integers is %s\" % (N, total))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you've written code externally, this is how you can examine it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "## %pycat 10.3-pool-multiprocessing.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In parallel functions, only the main process has access to the \"__main__\" function, so the remaining processes need to be told about any functions they need before we start, or any intermediate results, explicitly.\n",
    "\n",
    "The following script will **not work** because the \"myfunction\" function is created inside the \"__main__\" thread only:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(\"10.3-pool-multiprocessing-bad.py\", \"w\")\n",
    "f.write(\"\"\"\n",
    "from functools import reduce\n",
    "from multiprocessing import Pool, cpu_count, current_process\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # print the number of cores\n",
    "    print(\"Number of cores available equals %s\" % cpu_count())\n",
    "    N=50\n",
    "    # create a pool of workers\n",
    "    # start all worker processes\n",
    "    pool = Pool(processes= cpu_count())\n",
    "    def myfunction(x):\n",
    "        print(x)\n",
    "        return x * x\n",
    "    # create an array of integers, from 1 to N\n",
    "    r = range(1, N+1)\n",
    "    result = pool.map(myfunction, r)\n",
    "\n",
    "    total = reduce(lambda x, y: x + y, result)\n",
    "\n",
    "    print(\"The sum of the square of the first %s integers is %s\" % (N, total))\n",
    "\"\"\")\n",
    "f.close()\n",
    "## Don't run as it can mess up your processing environment\n",
    "## %run 10.3-pool-multiprocessing-bad.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Controlling the order of computations\n",
    "\n",
    "What did you notice about the order of computation and printing?\n",
    "\n",
    "In general it is a really bad idea to assume that printing appears to the screen in the correct order!\n",
    "\n",
    "(NB: Christopher's code used \"with Pool(processes=nprocs) as pool\" which didn't work for me due to python version issues. Multicore processing is still in active development....)\n",
    "\n",
    "When you can change the code above to use a function defined inside the __main__ loop. This **hangs**  because the worker nodes can't see it!  **CAREFUL** with this sort of thing.\n",
    "\n",
    "However, we can reuse our pool of processes in a straightforward way.\n",
    "\n",
    "We are also going to try using the `%%capture` jupyter magic (official phrase!) to capture the main output. This allows us to separate the multithreaded output (which is at best confusing) from the main output:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Worker 92280 calculating square of 1\n",
      "Worker 92280 calculating square of 2\n",
      "Worker 92280 calculating square of 3\n",
      "Worker 92280 calculating square of 4\n",
      "Worker 92280 calculating square of 37\n",
      "Worker 92280 calculating square of 38\n",
      "Worker 92280 calculating square of 39\n",
      "Worker 92280 calculating square of 40\n",
      "Worker 92280 calculating square of 69\n",
      "Worker 92280 calculating square of 70\n",
      "Worker 92280 calculating square of 71\n",
      "Worker 92280 calculating square of 72\n",
      "Worker 92280 calculating cube of 5\n",
      "Worker 92280 calculating cube of 6\n",
      "Worker 92280 calculating cube of 7\n",
      "Worker 92280 calculating cube of 8\n",
      "Worker 92280 calculating cube of 37\n",
      "Worker 92280 calculating cube of 38\n",
      "Worker 92280 calculating cube of 39\n",
      "Worker 92280 calculating cube of 40\n",
      "Worker 92280 calculating cube of 69\n",
      "Worker 92280 calculating cube of 70\n",
      "Worker 92280 calculating cube of 71\n",
      "Worker 92280 calculating cube of 72\n",
      "Worker 92283 calculating square of 21\n",
      "Worker 92283 calculating square of 22\n",
      "Worker 92283 calculating square of 23\n",
      "Worker 92283 calculating square of 24\n",
      "Worker 92283 calculating square of 49\n",
      "Worker 92283 calculating square of 50\n",
      "Worker 92283 calculating square of 51\n",
      "Worker 92283 calculating square of 52\n",
      "Worker 92283 calculating square of 81\n",
      "Worker 92283 calculating square of 82\n",
      "Worker 92283 calculating square of 83\n",
      "Worker 92283 calculating square of 84\n",
      "Worker 92283 calculating cube of 13\n",
      "Worker 92283 calculating cube of 14\n",
      "Worker 92283 calculating cube of 15\n",
      "Worker 92283 calculating cube of 16\n",
      "Worker 92283 calculating cube of 45\n",
      "Worker 92283 calculating cube of 46\n",
      "Worker 92283 calculating cube of 47\n",
      "Worker 92283 calculating cube of 48\n",
      "Worker 92283 calculating cube of 77\n",
      "Worker 92283 calculating cube of 78\n",
      "Worker 92283 calculating cube of 79\n",
      "Worker 92283 calculating cube of 80\n",
      "Worker 92281 calculating square of 5\n",
      "Worker 92281 calculating square of 6\n",
      "Worker 92281 calculating square of 7\n",
      "Worker 92281 calculating square of 8\n",
      "Worker 92281 calculating square of 41\n",
      "Worker 92281 calculating square of 42\n",
      "Worker 92281 calculating square of 43\n",
      "Worker 92281 calculating square of 44\n",
      "Worker 92281 calculating square of 73\n",
      "Worker 92281 calculating square of 74\n",
      "Worker 92281 calculating square of 75\n",
      "Worker 92281 calculating square of 76\n",
      "Worker 92281 calculating cube of 9\n",
      "Worker 92281 calculating cube of 10\n",
      "Worker 92281 calculating cube of 11\n",
      "Worker 92281 calculating cube of 12\n",
      "Worker 92281 calculating cube of 41\n",
      "Worker 92281 calculating cube of 42\n",
      "Worker 92281 calculating cube of 43\n",
      "Worker 92281 calculating cube of 44\n",
      "Worker 92281 calculating cube of 73\n",
      "Worker 92281 calculating cube of 74\n",
      "Worker 92281 calculating cube of 75\n",
      "Worker 92281 calculating cube of 76\n",
      "Worker 92285 calculating square of 17\n",
      "Worker 92285 calculating square of 18\n",
      "Worker 92285 calculating square of 19\n",
      "Worker 92285 calculating square of 20\n",
      "Worker 92285 calculating square of 53\n",
      "Worker 92285 calculating square of 54\n",
      "Worker 92285 calculating square of 55\n",
      "Worker 92285 calculating square of 56\n",
      "Worker 92285 calculating square of 85\n",
      "Worker 92285 calculating square of 86\n",
      "Worker 92285 calculating square of 87\n",
      "Worker 92285 calculating square of 88\n",
      "Worker 92285 calculating cube of 17\n",
      "Worker 92285 calculating cube of 18\n",
      "Worker 92285 calculating cube of 19\n",
      "Worker 92285 calculating cube of 20\n",
      "Worker 92285 calculating cube of 49\n",
      "Worker 92285 calculating cube of 50\n",
      "Worker 92285 calculating cube of 51\n",
      "Worker 92285 calculating cube of 52\n",
      "Worker 92285 calculating cube of 81\n",
      "Worker 92285 calculating cube of 82\n",
      "Worker 92285 calculating cube of 83\n",
      "Worker 92285 calculating cube of 84\n",
      "Worker 92286 calculating square of 25\n",
      "Worker 92286 calculating square of 26\n",
      "Worker 92286 calculating square of 27\n",
      "Worker 92286 calculating square of 28\n",
      "Worker 92286 calculating square of 61\n",
      "Worker 92286 calculating square of 62\n",
      "Worker 92286 calculating square of 63\n",
      "Worker 92286 calculating square of 64\n",
      "Worker 92286 calculating square of 93\n",
      "Worker 92286 calculating square of 94\n",
      "Worker 92286 calculating square of 95\n",
      "Worker 92286 calculating square of 96\n",
      "Worker 92286 calculating cube of 25\n",
      "Worker 92286 calculating cube of 26\n",
      "Worker 92286 calculating cube of 27\n",
      "Worker 92286 calculating cube of 28\n",
      "Worker 92286 calculating cube of 57\n",
      "Worker 92286 calculating cube of 58\n",
      "Worker 92286 calculating cube of 59\n",
      "Worker 92286 calculating cube of 60\n",
      "Worker 92286 calculating cube of 89\n",
      "Worker 92286 calculating cube of 90\n",
      "Worker 92286 calculating cube of 91\n",
      "Worker 92286 calculating cube of 92\n",
      "Worker 92284 calculating square of 29\n",
      "Worker 92284 calculating square of 30\n",
      "Worker 92284 calculating square of 31\n",
      "Worker 92284 calculating square of 32\n",
      "Worker 92284 calculating square of 57\n",
      "Worker 92284 calculating square of 58\n",
      "Worker 92284 calculating square of 59\n",
      "Worker 92284 calculating square of 60\n",
      "Worker 92284 calculating square of 89\n",
      "Worker 92284 calculating square of 90\n",
      "Worker 92284 calculating square of 91\n",
      "Worker 92284 calculating square of 92\n",
      "Worker 92284 calculating cube of 21\n",
      "Worker 92284 calculating cube of 22\n",
      "Worker 92284 calculating cube of 23\n",
      "Worker 92284 calculating cube of 24\n",
      "Worker 92284 calculating cube of 53\n",
      "Worker 92284 calculating cube of 54\n",
      "Worker 92284 calculating cube of 55\n",
      "Worker 92284 calculating cube of 56\n",
      "Worker 92284 calculating cube of 85\n",
      "Worker 92284 calculating cube of 86\n",
      "Worker 92284 calculating cube of 87\n",
      "Worker 92284 calculating cube of 88\n",
      "Worker 92279 calculating square of 9\n",
      "Worker 92279 calculating square of 10\n",
      "Worker 92279 calculating square of 11\n",
      "Worker 92279 calculating square of 12\n",
      "Worker 92279 calculating square of 33\n",
      "Worker 92279 calculating square of 34\n",
      "Worker 92279 calculating square of 35\n",
      "Worker 92279 calculating square of 36\n",
      "Worker 92279 calculating square of 65\n",
      "Worker 92279 calculating square of 66\n",
      "Worker 92279 calculating square of 67\n",
      "Worker 92279 calculating square of 68\n",
      "Worker 92279 calculating square of 97\n",
      "Worker 92279 calculating square of 98\n",
      "Worker 92279 calculating square of 99\n",
      "Worker 92279 calculating square of 100\n",
      "Worker 92279 calculating cube of 29\n",
      "Worker 92279 calculating cube of 30\n",
      "Worker 92279 calculating cube of 31\n",
      "Worker 92279 calculating cube of 32\n",
      "Worker 92279 calculating cube of 61\n",
      "Worker 92279 calculating cube of 62\n",
      "Worker 92279 calculating cube of 63\n",
      "Worker 92279 calculating cube of 64\n",
      "Worker 92279 calculating cube of 93\n",
      "Worker 92279 calculating cube of 94\n",
      "Worker 92279 calculating cube of 95\n",
      "Worker 92279 calculating cube of 96\n",
      "Worker 92282 calculating square of 13\n",
      "Worker 92282 calculating square of 14\n",
      "Worker 92282 calculating square of 15\n",
      "Worker 92282 calculating square of 16\n",
      "Worker 92282 calculating square of 45\n",
      "Worker 92282 calculating square of 46\n",
      "Worker 92282 calculating square of 47\n",
      "Worker 92282 calculating square of 48\n",
      "Worker 92282 calculating square of 77\n",
      "Worker 92282 calculating square of 78\n",
      "Worker 92282 calculating square of 79\n",
      "Worker 92282 calculating square of 80\n",
      "Worker 92282 calculating cube of 1\n",
      "Worker 92282 calculating cube of 2\n",
      "Worker 92282 calculating cube of 3\n",
      "Worker 92282 calculating cube of 4\n",
      "Worker 92282 calculating cube of 33\n",
      "Worker 92282 calculating cube of 34\n",
      "Worker 92282 calculating cube of 35\n",
      "Worker 92282 calculating cube of 36\n",
      "Worker 92282 calculating cube of 65\n",
      "Worker 92282 calculating cube of 66\n",
      "Worker 92282 calculating cube of 67\n",
      "Worker 92282 calculating cube of 68\n",
      "Worker 92282 calculating cube of 97\n",
      "Worker 92282 calculating cube of 98\n",
      "Worker 92282 calculating cube of 99\n",
      "Worker 92282 calculating cube of 100\n"
     ]
    }
   ],
   "source": [
    "%%capture captured\n",
    "f = open(\"10.3-pool-twice.py\", \"w\")\n",
    "f.write(\"\"\"\n",
    "from functools import reduce\n",
    "from multiprocessing import Pool, cpu_count, current_process\n",
    "from time import sleep\n",
    "\n",
    "def square(x):\n",
    "    \\\"\\\"\\\"Function to return the square of the argument\\\"\\\"\\\"\n",
    "    print(\"Worker %s calculating square of %s\" % (current_process().pid, x))\n",
    "    sleep(0.01)\n",
    "    return x * x\n",
    "\n",
    "def cube(x):\n",
    "    \\\"\\\"\\\"Function to return the cube of the argument\\\"\\\"\\\"\n",
    "    print(\"Worker %s calculating cube of %s\" % (current_process().pid, x))\n",
    "    return x * x * x\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # print the number of cores\n",
    "    print(\"Number of cores available equals %s\" % cpu_count())\n",
    "    N=100\n",
    "    # create a pool of workers\n",
    "    # start all worker processes\n",
    "    pool = Pool(processes= cpu_count()) ## THIS is where all of the memory state is \n",
    "    ## created and all of the processes \"know about\" everything above. So they \"know\" N\n",
    "    ## and hence all compute their own version of r correctly.\n",
    "    \n",
    "    # create an array of 5000 integers, from 1 to N \n",
    "    r = range(1, N+1)\n",
    "    squares = pool.map(square, r)\n",
    "    totalsquares = reduce(lambda x, y: x + y, squares)\n",
    "    print(\"The sum of the square of the first %s integers is %s\" % (N, totalsquares))\n",
    "    cubes = pool.map(cube, r)\n",
    "    totalcubes = reduce(lambda x, y: x + y, cubes)\n",
    "    print(\"The sum of the cube of the first %s integers is %s\" % (N, totalcubes))\n",
    "\"\"\")\n",
    "f.close()\n",
    "%run -i 10.3-pool-twice.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of cores available equals 8\n",
      "The sum of the square of the first 100 integers is 338350\n",
      "The sum of the cube of the first 100 integers is 25502500\n"
     ]
    }
   ],
   "source": [
    "captured()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice the **order** of these outputs can vary quite considerably...\n",
    "\n",
    "### 3.4 multiple inputs to map using starmap\n",
    "\n",
    "To use mapping on multiple inputs, we have to either:\n",
    "\n",
    "* create a tuple of the arguments\n",
    "* or pass it through using **zip** and switch from the **map** to **starmap**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7, 9, 11, 13, 15]\n"
     ]
    }
   ],
   "source": [
    "f = open(\"10.3-pool-starmap.py\", \"w\")\n",
    "f.write(\"\"\"\n",
    "from multiprocessing import Pool\n",
    "\n",
    "def add(x, y):\n",
    "    \\\"\\\"\\\"Return the sum of the tuple of two arguments\\\"\\\"\\\"\n",
    "    return x + y\n",
    "\n",
    "a = [1, 2, 3, 4, 5]\n",
    "b = [6, 7, 8, 9, 10]\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    with Pool() as pool:\n",
    "        result = pool.starmap(add, zip(a,b))\n",
    "\n",
    "    print(result)\n",
    "\"\"\")\n",
    "f.close()\n",
    "%run -i 10.3-pool-starmap.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again using `%%capture`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture captured\n",
    "%run -i 10.3-pool-starmap.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7, 9, 11, 13, 15]\n"
     ]
    }
   ],
   "source": [
    "captured()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are other implementation niggles, such as support for lambda functions (which is missing) etc. These may be addressed in newer versions or alternative packages.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. asynchronous functions\n",
    "\n",
    "We saw above that the \"print\" statements were out of order. This is because the threads had to \"race\" to collect the next job, and also race to print to the screen. There is only one job queue and one screen.\n",
    "\n",
    "The following script performs jobs asynchronously. You should see that there are 3 workers, which complete one task before taking the next."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Master process is PID 91739\n",
      "Process 95964 going to sleep for 3 second(s)\n",
      "Process 95964 waking up\n",
      "Process 95964 going to sleep for 5 second(s)\n",
      "Process 95964 waking up\n",
      "Process 95965 going to sleep for 2 second(s)\n",
      "Process 95965 waking up\n",
      "Process 95965 going to sleep for 4 second(s)\n",
      "Process 95965 waking up\n",
      "Process 95965 going to sleep for 6 second(s)\n",
      "Process 95965 waking up\n",
      "Process 95966 going to sleep for 8 second(s)\n",
      "Process 95966 waking up\n",
      "Process 95966 going to sleep for 7 second(s)\n",
      "Process 95966 waking up\n",
      "Result is [8, 2, 3, 4, 5, 6, 7]\n"
     ]
    }
   ],
   "source": [
    "f = open(\"10.3-pool-slow.py\", \"w\")\n",
    "f.write(\"\"\"\n",
    "import time\n",
    "from multiprocessing import Pool, current_process\n",
    "\n",
    "def slow_function(nsecs):\n",
    "    \\\"\\\"\\\"\n",
    "    Function that sleeps for 'nsecs' seconds, returning\n",
    "    the number of seconds that it slept\n",
    "    \\\"\\\"\\\"\n",
    "    print(\"Process %s going to sleep for %s second(s)\" % (current_process().pid, nsecs))\n",
    "    # use the time.sleep function to sleep for nsecs seconds\n",
    "    time.sleep(nsecs)\n",
    "    print(\"Process %s waking up\" % current_process().pid)\n",
    "    return nsecs\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"Master process is PID %s\" % current_process().pid)\n",
    "\n",
    "    with Pool(3) as pool:\n",
    "        r = pool.map(slow_function, [8,2,3,4,5,6,7])\n",
    "\n",
    "    print(\"Result is %s\" % r)\n",
    "\"\"\")\n",
    "f.close()\n",
    "%run -i 10.3-pool-slow.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sometimes we don't want to wait for a computation to be completed before distributing some other computation. \n",
    "\n",
    "The async versions of map, apply, etc return immediately, providing a \"future\" object. These are evaluated asyncyronously. They can be blocked (here via \"wait\") and allow a [callback](https://docs.python.org/3.8/library/multiprocessing.html?highlight=map_async#multiprocessing.pool.Pool.map_async) which runs on completion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Master process is PID 91739\n",
      "Starting r1 pool\n",
      "Starting r2 pool\n",
      "Result one is [1, 2, 3, 4, 5]\n",
      "Result two is [0.5, 0.5, 0.5, 0.5, 0.5]\n",
      "Result appended is [1, 2, 3, 4, 5, 0.5, 0.5, 0.5, 0.5, 0.5]\n",
      "Process 98211 going to sleep for 1 second(s)\n",
      "Process 98211 waking up\n",
      "Process 98211 going to sleep for 4 second(s)\n",
      "Process 98211 waking up\n",
      "Process 98211 going to sleep for 0.5 second(s)\n",
      "Process 98211 waking up\n",
      "Process 98211 going to sleep for 0.5 second(s)\n",
      "Process 98211 waking up\n",
      "Process 98213 going to sleep for 2 second(s)\n",
      "Process 98213 waking up\n",
      "Process 98213 going to sleep for 5 second(s)\n",
      "Process 98213 waking up\n",
      "Process 98213 going to sleep for 0.5 second(s)\n",
      "Process 98213 waking up\n",
      "Process 98212 going to sleep for 3 second(s)\n",
      "Process 98212 waking up\n",
      "Process 98212 going to sleep for 0.5 second(s)\n",
      "Process 98212 waking up\n",
      "Process 98212 going to sleep for 0.5 second(s)\n",
      "Process 98212 waking up\n"
     ]
    }
   ],
   "source": [
    "f = open(\"10.3-pool-async.py\", \"w\")\n",
    "f.write(\"\"\"\n",
    "import time\n",
    "from multiprocessing import Pool, current_process\n",
    "\n",
    "def slow_function(nsecs):\n",
    "    \\\"\\\"\\\"\n",
    "    Function that sleeps for 'nsecs' seconds, returning\n",
    "    the number of seconds that it slept\n",
    "    \\\"\\\"\\\"\n",
    "    print(\"Process %s going to sleep for %s second(s)\" % (current_process().pid, nsecs))\n",
    "    # use the time.sleep function to sleep for nsecs seconds\n",
    "    time.sleep(nsecs)\n",
    "    print(\"Process %s waking up\" % current_process().pid)\n",
    "    return nsecs\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"Master process is PID %s\" % current_process().pid)\n",
    "    r=[]\n",
    "    with Pool(3) as pool:\n",
    "        print(\"Starting r1 pool\")\n",
    "        r1 = pool.map_async(slow_function, [1,2,3,4,5],callback=r.extend)\n",
    "        # r1 starts first, finishes last\n",
    "        \n",
    "        ## Compare the following:\n",
    "        r1.wait() # Uncomment this\n",
    "        print(\"Starting r2 pool\")\n",
    "        r2 = pool.map_async(slow_function, [0.5,0.5,0.5,0.5,0.5],callback=r.extend)\n",
    "\n",
    "        ## With this:\n",
    "        r1.wait() # Comment out this \n",
    "        \n",
    "        r2.wait()\n",
    "        print(\"Result one is %s\" % r1.get())\n",
    "        print(\"Result two is %s\" % r2.get())\n",
    "        print(\"Result appended is %s\" % r)\n",
    "\"\"\")\n",
    "f.close()\n",
    "%run -i 10.3-pool-async.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Asynchronous computation \n",
    "\n",
    "Here we encountered \"futures\" which are computations that may not have completed and therefore may not be available.\n",
    "\n",
    "Futures are a very common variable type in parallel programming across many languages. Futures provide several common functions;\n",
    "\n",
    "* Block (wait) until the result is available. In multiprocessing, this is via the .wait() function, e.g. r1.wait() in the above script.\n",
    "* Retrieve the result when it is available (blocking until it is available). This is the .get() function, e.g. r1.get().\n",
    "* Test whether or not the result is available. This is the .ready() function, which returns True when the asynchronous function has finished and the result is available via .get().\n",
    "* Test whether or not the function was a success, e.g. whether or not an exception was raised when running the function. This is the .successful() function, which returns True if the asynchronous function completed without raising an exception. Note that this function should only be called after the result is available (e.g. when .ready() returns True)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Additional Information\n",
    "\n",
    "There are additional ways to help parallelisation be efficient. One is the idea of \"chunksize\", or how many commands get sent to each worker; it is a parameter of starmap/map."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
